import axios from 'axios';
import logger from '../utils/logger.js';

// URL for the Flask ML Service
const ML_SERVICE_URL = process.env.ML_SERVICE_URL || 'http://127.0.0.1:1240';

class MLService {
  /**
   * Get predictive maintenance prediction for a single equipment
   * @param {Object} features - The features required by the model
   * @returns {Promise<Object>} - The prediction result
   */
  async getPrediction(features) {
    try {
      // Prepare payload matches the exact keys expected by app.py
      const payload = {
        Temperature_C: features.temperature || 0,
        Vibration_mms: features.vibration || 0,
        Energy_Consumption_W: features.energyConsumption || 0,
        Days_Since_Weekly_Maintenance: features.daysSinceMaintenance || 0
      };

      // --- ADDED LOGS ---
      logger.info(`ü§ñ [ML Service] Sending POST to ${ML_SERVICE_URL}/predict`);
      logger.info(`üì¶ [ML Service] Payload: ${JSON.stringify(payload, null, 2)}`);
      // ------------------

      const response = await axios.post(`${ML_SERVICE_URL}/predict`, payload);
      
      // --- LOG RESPONSE ---
      logger.info(`‚úÖ [ML Service] Response: ${JSON.stringify(response.data)}`);
      // --------------------

      return {
        prediction: response.data.prediction, // 0 (No Issue) or 1 (Maintenance Needed)
        probability: response.data.probability_percentage,
        status: 'success'
      };
    } catch (error) {
      logger.error(`‚ùå [ML Service] Error: ${error.message}`);
      if (error.response) {
        logger.error(`   Server responded with: ${JSON.stringify(error.response.data)}`);
      }
      return {
        prediction: 0,
        probability: 0,
        status: 'error',
        error: error.message
      };
    }
  }
}

export default new MLService();